{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "# Data\n",
    "housing = fetch_california_housing()\n",
    "X, y = housing['data'], housing['target']\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, shuffle=True, random_state=43)\n",
    "\n",
    "# Define the base pipeline steps\n",
    "base_pipeline = [\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1 - Create 5 pipelines with 5 different models as final estimator (keep the imputer and scaler unchanged):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the models\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'SVM': SVR(),\n",
    "    'Decision Tree': DecisionTreeRegressor(random_state=43),\n",
    "    'Random Forest': RandomForestRegressor(random_state=43),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(random_state=43)\n",
    "}\n",
    "\n",
    "# Function to evaluate model\n",
    "def evaluate_model(model, X, y):\n",
    "    y_pred = model.predict(X)\n",
    "    r2 = r2_score(y, y_pred)\n",
    "    mae = mean_absolute_error(y, y_pred)\n",
    "    mse = mean_squared_error(y, y_pred)\n",
    "    return r2, mae, mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 - For each algorithm, print the R2, MSE and MAE on both train set and test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "~~~\n",
      "Linear Regression\n",
      "\n",
      "TRAIN\n",
      "r2 score:        0.6054131599242079\n",
      "MAE:             0.5330920012614552\n",
      "MSE:             0.5273648371379568\n",
      "\n",
      "TEST\n",
      "r2 score:        0.6128959462132963\n",
      "MAE:             0.5196420310323715\n",
      "MSE:             0.49761195027083815\n",
      "\n",
      "~~~\n",
      "SVM\n",
      "\n",
      "TRAIN\n",
      "r2 score:        0.7496108582936637\n",
      "MAE:             0.383564516332599\n",
      "MSE:             0.3346447867133921\n",
      "\n",
      "TEST\n",
      "r2 score:        0.729508064989969\n",
      "MAE:             0.3897680598426778\n",
      "MSE:             0.34771017765429973\n",
      "\n",
      "~~~\n",
      "Decision Tree\n",
      "\n",
      "TRAIN\n",
      "r2 score:        1.0\n",
      "MAE:             4.221907539810565e-17\n",
      "MSE:             9.24499456646287e-32\n",
      "\n",
      "TEST\n",
      "r2 score:        0.6228217144931267\n",
      "MAE:             0.4403051356589147\n",
      "MSE:             0.4848526395290697\n",
      "\n",
      "~~~\n",
      "Random Forest\n",
      "\n",
      "TRAIN\n",
      "r2 score:        0.9741263135396302\n",
      "MAE:             0.12000198560508221\n",
      "MSE:             0.03458015083247723\n",
      "\n",
      "TEST\n",
      "r2 score:        0.8119778189909694\n",
      "MAE:             0.3194169859011629\n",
      "MSE:             0.24169750554364758\n",
      "\n",
      "~~~\n",
      "Gradient Boosting\n",
      "\n",
      "TRAIN\n",
      "r2 score:        0.8042086499063386\n",
      "MAE:             0.35656543036682264\n",
      "MSE:             0.26167490389525294\n",
      "\n",
      "TEST\n",
      "r2 score:        0.7895081234643192\n",
      "MAE:             0.36455447680396397\n",
      "MSE:             0.27058170064218096\n"
     ]
    }
   ],
   "source": [
    "# Create pipelines and evaluate models\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\n~~~\\n{model_name}\\n\")\n",
    "    \n",
    "    # Create pipeline\n",
    "    pipeline = base_pipeline + [('model', model)]\n",
    "    pipe = Pipeline(pipeline)\n",
    "    \n",
    "    # Fit the model\n",
    "    pipe.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate on train set\n",
    "    train_r2, train_mae, train_mse = evaluate_model(pipe, X_train, y_train)\n",
    "    print(\"TRAIN\")\n",
    "    print(f\"r2 score:        {train_r2}\")\n",
    "    print(f\"MAE:             {train_mae}\")\n",
    "    print(f\"MSE:             {train_mse}\")\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    test_r2, test_mae, test_mse = evaluate_model(pipe, X_test, y_test)\n",
    "    print(\"\\nTEST\")\n",
    "    print(f\"r2 score:        {test_r2}\")\n",
    "    print(f\"MAE:             {test_mae}\")\n",
    "    print(f\"MSE:             {test_mse}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArtificialIntelligence",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
